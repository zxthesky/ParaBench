nohup: ignoring input
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /data/xzhang/model_parameter/bert/bert_based_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/xzhang/anaconda3/envs/LLM/lib/python3.11/site-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
-----------------starting training ----------------------
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [18:25<5:50:00, 1105.27s/it] 10%|█         | 2/20 [36:54<5:32:16, 1107.57s/it] 15%|█▌        | 3/20 [55:45<5:16:50, 1118.28s/it] 20%|██        | 4/20 [1:14:03<4:56:04, 1110.31s/it] 25%|██▌       | 5/20 [1:32:12<4:35:37, 1102.53s/it] 30%|███       | 6/20 [1:50:19<4:16:04, 1097.47s/it] 35%|███▌      | 7/20 [2:08:34<3:57:33, 1096.45s/it] 40%|████      | 8/20 [2:26:43<3:38:50, 1094.18s/it] 45%|████▌     | 9/20 [2:44:55<3:20:28, 1093.49s/it] 50%|█████     | 10/20 [3:03:17<3:02:41, 1096.19s/it]step: 1000; loss: 0.6350035667419434
step: 2000; loss: 0.6008551120758057
step: 3000; loss: 0.6624836325645447
step: 4000; loss: 0.46552348136901855
step: 5000; loss: 0.44224461913108826
step: 6000; loss: 0.904223620891571
step: 7000; loss: 0.8730614185333252
step: 8000; loss: 0.5879112482070923
step: 9000; loss: 0.6956757307052612
step: 10000; loss: 0.5326327085494995
step: 11000; loss: 0.5048692226409912
step: 12000; loss: 0.5714300870895386
step: 13000; loss: 0.4300653338432312
step: 14000; loss: 0.7196743488311768
step: 15000; loss: 0.8266658186912537
step: 16000; loss: 0.44159767031669617
step: 17000; loss: 0.4856225252151489
step: 18000; loss: 0.7235676646232605
epoch: 0; loss: 0.4724085330963135
'--eval--'  average loss: 0.5682673454284668
step: 1000; loss: 0.7369827628135681
step: 2000; loss: 1.0826146602630615
step: 3000; loss: 0.9223935604095459
step: 4000; loss: 0.483722448348999
step: 5000; loss: 0.4086816906929016
step: 6000; loss: 0.471290647983551
step: 7000; loss: 0.4808277487754822
step: 8000; loss: 0.5826855301856995
step: 9000; loss: 0.41904503107070923
step: 10000; loss: 0.4474336504936218
step: 11000; loss: 0.4518723487854004
step: 12000; loss: 0.5400127172470093
step: 13000; loss: 0.46002158522605896
step: 14000; loss: 0.5955068469047546
step: 15000; loss: 0.3828962743282318
step: 16000; loss: 0.4468686282634735
step: 17000; loss: 0.5504453182220459
step: 18000; loss: 0.3678867816925049
epoch: 1; loss: 0.5592750310897827
'--eval--'  average loss: 0.5523847937583923
step: 1000; loss: 0.4050760865211487
step: 2000; loss: 0.6191577911376953
step: 3000; loss: 0.4116227626800537
step: 4000; loss: 0.743577241897583
step: 5000; loss: 0.39593857526779175
step: 6000; loss: 0.532148003578186
step: 7000; loss: 1.0574371814727783
step: 8000; loss: 0.4637148380279541
step: 9000; loss: 0.3833687901496887
step: 10000; loss: 0.6169164776802063
step: 11000; loss: 0.3922080993652344
step: 12000; loss: 0.45423635840415955
step: 13000; loss: 0.5941367149353027
step: 14000; loss: 0.4722408652305603
step: 15000; loss: 0.38633084297180176
step: 16000; loss: 0.6624366641044617
step: 17000; loss: 0.5631084442138672
step: 18000; loss: 0.36687082052230835
epoch: 2; loss: 0.46811509132385254
'--eval--'  average loss: 0.5444620251655579
step: 1000; loss: 0.5198601484298706
step: 2000; loss: 0.6148333549499512
step: 3000; loss: 1.0707223415374756
step: 4000; loss: 1.01426362991333
step: 5000; loss: 0.5012634992599487
step: 6000; loss: 0.3928699493408203
step: 7000; loss: 0.4336807131767273
step: 8000; loss: 0.39202260971069336
step: 9000; loss: 0.5771417617797852
step: 10000; loss: 0.4733554720878601
step: 11000; loss: 0.3492623269557953
step: 12000; loss: 0.3376198410987854
step: 13000; loss: 0.5963296890258789
step: 14000; loss: 0.40700334310531616
step: 15000; loss: 0.33044981956481934
step: 16000; loss: 0.3537759780883789
step: 17000; loss: 0.602545976638794
step: 18000; loss: 0.4594988226890564
epoch: 3; loss: 0.5893371105194092
'--eval--'  average loss: 0.5391179919242859
step: 1000; loss: 0.36507540941238403
step: 2000; loss: 0.2308526635169983
step: 3000; loss: 0.34212422370910645
step: 4000; loss: 0.7275528311729431
step: 5000; loss: 0.783501386642456
step: 6000; loss: 1.0687440633773804
step: 7000; loss: 0.37434226274490356
step: 8000; loss: 0.4866119623184204
step: 9000; loss: 0.5441808104515076
step: 10000; loss: 0.2600873112678528
step: 11000; loss: 0.26391124725341797
step: 12000; loss: 0.7016503810882568
step: 13000; loss: 0.730839192867279
step: 14000; loss: 0.2600818872451782
step: 15000; loss: 0.6162556409835815
step: 16000; loss: 0.4319189190864563
step: 17000; loss: 0.500030517578125
step: 18000; loss: 0.6178262233734131
epoch: 4; loss: 0.35661599040031433
'--eval--'  average loss: 0.5738863348960876
step: 1000; loss: 0.2738676071166992
step: 2000; loss: 0.4485752582550049
step: 3000; loss: 0.5596041679382324
step: 4000; loss: 0.12603536248207092
step: 5000; loss: 0.1337398886680603
step: 6000; loss: 0.19636695086956024
step: 7000; loss: 0.662679135799408
step: 8000; loss: 0.6284940242767334
step: 9000; loss: 0.37701278924942017
step: 10000; loss: 0.37695538997650146
step: 11000; loss: 1.3463667631149292
step: 12000; loss: 0.6783878207206726
step: 13000; loss: 0.8444476127624512
step: 14000; loss: 0.4934775233268738
step: 15000; loss: 0.37417691946029663
step: 16000; loss: 0.22912567853927612
step: 17000; loss: 0.42132019996643066
step: 18000; loss: 0.38743874430656433
epoch: 5; loss: 0.33844441175460815
'--eval--'  average loss: 0.5554335117340088
step: 1000; loss: 0.2347993701696396
step: 2000; loss: 0.6611064672470093
step: 3000; loss: 0.4002712666988373
step: 4000; loss: 0.5837210416793823
step: 5000; loss: 0.37303006649017334
step: 6000; loss: 0.25892385840415955
step: 7000; loss: 0.1735239028930664
step: 8000; loss: 0.07430711388587952
step: 9000; loss: 0.12398380041122437
step: 10000; loss: 0.30417487025260925
step: 11000; loss: 0.5411543250083923
step: 12000; loss: 0.6853799819946289
step: 13000; loss: 0.420230507850647
step: 14000; loss: 0.0918615385890007
step: 15000; loss: 0.25198230147361755
step: 16000; loss: 0.2435174286365509
step: 17000; loss: 0.15187014639377594
step: 18000; loss: 0.7325970530509949
epoch: 6; loss: 0.21311049163341522
'--eval--'  average loss: 0.5866737365722656
step: 1000; loss: 0.2612342834472656
step: 2000; loss: 0.15963196754455566
step: 3000; loss: 0.23514890670776367
step: 4000; loss: 0.35225486755371094
step: 5000; loss: 0.8769668340682983
step: 6000; loss: 0.924513041973114
step: 7000; loss: 0.4353220462799072
step: 8000; loss: 0.7858496904373169
step: 9000; loss: 0.3828739523887634
step: 10000; loss: 0.08693031966686249
step: 11000; loss: 0.2818707823753357
step: 12000; loss: 0.07524824142456055
step: 13000; loss: 0.3407573103904724
step: 14000; loss: 1.00650954246521
step: 15000; loss: 0.08202176541090012
step: 16000; loss: 1.136854648590088
step: 17000; loss: 0.395987331867218
step: 18000; loss: 0.6639480590820312
epoch: 7; loss: 0.25514140725135803
'--eval--'  average loss: 0.5784192085266113
step: 1000; loss: 0.14131470024585724
step: 2000; loss: 0.5105780363082886
step: 3000; loss: 0.5514640808105469
step: 4000; loss: 0.05602309852838516
step: 5000; loss: 0.2569372355937958
step: 6000; loss: 0.16518884897232056
step: 7000; loss: 0.07138099521398544
step: 8000; loss: 0.3967512249946594
step: 9000; loss: 0.05857185646891594
step: 10000; loss: 0.646173894405365
step: 11000; loss: 0.48900145292282104
step: 12000; loss: 0.08665424585342407
step: 13000; loss: 0.06168972700834274
step: 14000; loss: 0.451223224401474
step: 15000; loss: 0.08610847592353821
step: 16000; loss: 0.2598307728767395
step: 17000; loss: 0.22047829627990723
step: 18000; loss: 0.5302543640136719
epoch: 8; loss: 0.7940984964370728
'--eval--'  average loss: 0.6100847721099854
step: 1000; loss: 0.0590137243270874
step: 2000; loss: 0.13153089582920074
step: 3000; loss: 0.07926085591316223
step: 4000; loss: 0.038767412304878235
step: 5000; loss: 0.06821387261152267
step: 6000; loss: 0.20802545547485352
step: 7000; loss: 1.0916733741760254
step: 8000; loss: 0.2886820435523987
step: 9000; loss: 0.7599657773971558
step: 10000; loss: 0.09482818096876144
step: 11000; loss: 0.19683849811553955
step: 12000; loss: 0.1956821084022522
step: 13000; loss: 0.06371904909610748
step: 14000; loss: 0.2420758306980133
step: 15000; loss: 0.29882359504699707
step: 16000; loss: 0.3574450612068176
step: 17000; loss: 0.017191994935274124
step: 18000; loss: 0.019044633954763412
epoch: 9; loss: 0.1941438764333725
'--eval--'  average loss: 0.6197216510772705
step: 1000; loss: 0.04238298162817955
step: 2000; loss: 0.14988169074058533
step: 3000; loss: 0.010075332596898079
step: 4000; loss: 0.039277829229831696
step: 5000; loss: 0.1678868532180786
step: 6000; loss: 0.08919398486614227
step: 7000; loss: 0.18930284678936005
step: 8000; loss: 1.477661371231079
step: 9000; loss: 1.1864831447601318
step: 10000; loss: 0.23425331711769104
step: 11000; loss: 0.40194329619407654
step: 12000; loss: 0.13496333360671997
step: 13000; loss: 0.24487486481666565
step: 14000; loss: 0.23986487090587616
step: 15000; loss: 0.2648291289806366
 55%|█████▌    | 11/20 [3:21:44<2:44:53, 1099.27s/it] 60%|██████    | 12/20 [3:40:04<2:26:37, 1099.69s/it] 65%|██████▌   | 13/20 [3:58:13<2:07:55, 1096.45s/it] 70%|███████   | 14/20 [4:16:28<1:49:36, 1096.01s/it] 75%|███████▌  | 15/20 [4:34:42<1:31:16, 1095.30s/it] 80%|████████  | 16/20 [4:52:49<1:12:51, 1092.93s/it] 85%|████████▌ | 17/20 [5:11:07<54:42, 1094.25s/it]   90%|█████████ | 18/20 [5:29:32<36:35, 1097.72s/it] 95%|█████████▌| 19/20 [5:47:50<18:17, 1097.69s/it]100%|██████████| 20/20 [6:06:14<00:00, 1099.53s/it]100%|██████████| 20/20 [6:06:14<00:00, 1098.72s/it]
step: 16000; loss: 0.013501368463039398
step: 17000; loss: 0.5109493136405945
step: 18000; loss: 0.09361385554075241
epoch: 10; loss: 0.3351014256477356
'--eval--'  average loss: 0.5311575531959534
step: 1000; loss: 0.21740686893463135
step: 2000; loss: 0.01868378184735775
step: 3000; loss: 0.13253949582576752
step: 4000; loss: 0.06392549723386765
step: 5000; loss: 0.18340438604354858
step: 6000; loss: 0.5120029449462891
step: 7000; loss: 0.05784377455711365
step: 8000; loss: 0.6046217679977417
step: 9000; loss: 0.47595667839050293
step: 10000; loss: 0.27030909061431885
step: 11000; loss: 0.21391481161117554
step: 12000; loss: 0.03004550002515316
step: 13000; loss: 0.24650540947914124
step: 14000; loss: 0.007597282063215971
step: 15000; loss: 0.21827015280723572
step: 16000; loss: 1.2080984115600586
step: 17000; loss: 0.524379312992096
step: 18000; loss: 0.19422632455825806
epoch: 11; loss: 0.17420530319213867
'--eval--'  average loss: 0.6309831142425537
step: 1000; loss: 0.3688544034957886
step: 2000; loss: 0.2643904387950897
step: 3000; loss: 0.007275336422026157
step: 4000; loss: 0.031239274889230728
step: 5000; loss: 0.1234564408659935
step: 6000; loss: 0.4659624993801117
step: 7000; loss: 0.4483407437801361
step: 8000; loss: 0.010119536891579628
step: 9000; loss: 0.021092981100082397
step: 10000; loss: 0.648614764213562
step: 11000; loss: 0.12378689646720886
step: 12000; loss: 0.11612914502620697
step: 13000; loss: 0.03187292069196701
step: 14000; loss: 0.018722275272011757
step: 15000; loss: 0.41223859786987305
step: 16000; loss: 0.24780964851379395
step: 17000; loss: 0.789341390132904
step: 18000; loss: 0.2736702859401703
epoch: 12; loss: 0.03663847967982292
'--eval--'  average loss: 0.6566694378852844
step: 1000; loss: 0.33161479234695435
step: 2000; loss: 0.1617017388343811
step: 3000; loss: 0.005835609510540962
step: 4000; loss: 0.10235687345266342
step: 5000; loss: 0.23269496858119965
step: 6000; loss: 0.18706011772155762
step: 7000; loss: 0.0371687225997448
step: 8000; loss: 0.01533848699182272
step: 9000; loss: 0.44153091311454773
step: 10000; loss: 0.9064354300498962
step: 11000; loss: 0.27765101194381714
step: 12000; loss: 0.006753562018275261
step: 13000; loss: 0.09761273860931396
step: 14000; loss: 0.012325469404459
step: 15000; loss: 0.11574497073888779
step: 16000; loss: 0.318954199552536
step: 17000; loss: 0.2575913071632385
step: 18000; loss: 0.39366471767425537
epoch: 13; loss: 0.19236859679222107
'--eval--'  average loss: 0.6064628958702087
step: 1000; loss: 0.006618616171181202
step: 2000; loss: 0.004444786347448826
step: 3000; loss: 0.15587881207466125
step: 4000; loss: 0.5605267882347107
step: 5000; loss: 0.008348188363015652
step: 6000; loss: 0.29608723521232605
step: 7000; loss: 0.013827539049088955
step: 8000; loss: 0.008159518241882324
step: 9000; loss: 0.3294944167137146
step: 10000; loss: 0.20123445987701416
step: 11000; loss: 0.0510311983525753
step: 12000; loss: 0.004884482827037573
step: 13000; loss: 0.07028072327375412
step: 14000; loss: 0.17679747939109802
step: 15000; loss: 0.005551951937377453
step: 16000; loss: 0.21117186546325684
step: 17000; loss: 0.3593146502971649
step: 18000; loss: 0.279959499835968
epoch: 14; loss: 0.1494380682706833
'--eval--'  average loss: 0.7031497955322266
step: 1000; loss: 0.011729820631444454
step: 2000; loss: 0.23488573729991913
step: 3000; loss: 0.28265637159347534
step: 4000; loss: 0.20753678679466248
step: 5000; loss: 0.004591134376823902
step: 6000; loss: 0.019619792699813843
step: 7000; loss: 0.09714927524328232
step: 8000; loss: 0.0043895612470805645
step: 9000; loss: 0.08049079030752182
step: 10000; loss: 0.07923014461994171
step: 11000; loss: 0.4691550135612488
step: 12000; loss: 0.372752845287323
step: 13000; loss: 0.13017022609710693
step: 14000; loss: 0.26805466413497925
step: 15000; loss: 0.005469788797199726
step: 16000; loss: 0.004956550430506468
step: 17000; loss: 0.10435281693935394
step: 18000; loss: 0.17225848138332367
epoch: 15; loss: 0.19596467912197113
'--eval--'  average loss: 0.6563869118690491
step: 1000; loss: 0.24448156356811523
step: 2000; loss: 0.009616936556994915
step: 3000; loss: 0.014887209981679916
step: 4000; loss: 0.17986588180065155
step: 5000; loss: 0.0037124138325452805
step: 6000; loss: 0.0044413222931325436
step: 7000; loss: 0.09344424307346344
step: 8000; loss: 0.022961337119340897
step: 9000; loss: 0.0042488533072173595
step: 10000; loss: 0.08658715337514877
step: 11000; loss: 0.01811712607741356
step: 12000; loss: 0.4623751640319824
step: 13000; loss: 0.003670557402074337
step: 14000; loss: 0.024825945496559143
step: 15000; loss: 0.10061027854681015
step: 16000; loss: 0.25438669323921204
step: 17000; loss: 0.27834221720695496
step: 18000; loss: 0.006585344206541777
epoch: 16; loss: 1.1019662618637085
'--eval--'  average loss: 0.7386810779571533
step: 1000; loss: 0.01128707267343998
step: 2000; loss: 0.27807268500328064
step: 3000; loss: 0.3430766463279724
step: 4000; loss: 0.0072977421805262566
step: 5000; loss: 0.2821424603462219
step: 6000; loss: 0.016805797815322876
step: 7000; loss: 0.085326187312603
step: 8000; loss: 0.23031824827194214
step: 9000; loss: 0.020519457757472992
step: 10000; loss: 0.058178991079330444
step: 11000; loss: 0.0028162766247987747
step: 12000; loss: 0.052428893744945526
step: 13000; loss: 0.004250051453709602
step: 14000; loss: 0.25996124744415283
step: 15000; loss: 0.0032311927061527967
step: 16000; loss: 0.004138534888625145
step: 17000; loss: 0.13906040787696838
step: 18000; loss: 0.003472032491117716
epoch: 17; loss: 0.2641255557537079
'--eval--'  average loss: 0.7045378684997559
step: 1000; loss: 0.003546822816133499
step: 2000; loss: 0.08527743071317673
step: 3000; loss: 0.003517837729305029
step: 4000; loss: 0.0061768777668476105
step: 5000; loss: 0.967814564704895
step: 6000; loss: 0.2709552049636841
step: 7000; loss: 0.003614439396187663
step: 8000; loss: 0.451643705368042
step: 9000; loss: 0.18214242160320282
step: 10000; loss: 0.2564689517021179
step: 11000; loss: 0.0045858086086809635
step: 12000; loss: 0.2346421480178833
step: 13000; loss: 0.011902231723070145
step: 14000; loss: 0.00545310927554965
step: 15000; loss: 0.680818498134613
step: 16000; loss: 0.2668991684913635
step: 17000; loss: 0.008534390479326248
step: 18000; loss: 0.007067529484629631
epoch: 18; loss: 0.022704914212226868
'--eval--'  average loss: 0.6838791370391846
step: 1000; loss: 0.0029935145284980536
step: 2000; loss: 0.41772398352622986
step: 3000; loss: 0.02599463425576687
step: 4000; loss: 0.0064810942858457565
step: 5000; loss: 0.003147164359688759
step: 6000; loss: 0.0029222823213785887
step: 7000; loss: 0.0038113673217594624
step: 8000; loss: 1.2635935544967651
step: 9000; loss: 0.01317538321018219
step: 10000; loss: 0.13641521334648132
step: 11000; loss: 0.0029522653203457594
step: 12000; loss: 0.022713951766490936
step: 13000; loss: 0.0036536797415465117
step: 14000; loss: 0.06761129945516586
step: 15000; loss: 0.007886319421231747
step: 16000; loss: 0.004997928626835346
step: 17000; loss: 0.016046373173594475
step: 18000; loss: 0.18097828328609467
epoch: 19; loss: 0.024896811693906784
'--eval--'  average loss: 0.6741006970405579
-------------test result------------------
--------------0.6805647474078976-----------------
